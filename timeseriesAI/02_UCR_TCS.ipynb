{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created by Ignacio Oguiza - email: oguiza@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:33:54.512402Z",
     "start_time": "2019-10-01T16:33:54.507048Z"
    }
   },
   "source": [
    "If you are using Google Colab uncomment the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:38:42.227769Z",
     "start_time": "2019-10-01T16:38:42.224773Z"
    }
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/timeseriesAI/timeseriesAI.git\n",
    "#%cd timeseriesAI\n",
    "#!pip install tslearn\n",
    "#!pip install pyts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:38:44.251012Z",
     "start_time": "2019-10-01T16:38:42.230947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oguizadl/timeseriesAI\n",
      "fastai : 1.0.58\n",
      "torch  : 1.3.0\n",
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "import fastai, os\n",
    "from fastai_timeseries import *\n",
    "from torchtimeseries.models import *\n",
    "path = Path(os.getcwd())\n",
    "print(path)\n",
    "print('fastai :', fastai.__version__)\n",
    "print('torch  :', torch.__version__)\n",
    "print('device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_UCR_test(iters, epochs, datasets, arch, \n",
    "                 bs=64, max_lr=3e-3, pct_start=.7, warmup=False, wd=1e-2, metrics=[accuracy], \n",
    "                 scale_type ='standardize', scale_by_channel=True, scale_by_sample=False, scale_range=(-1, 1), \n",
    "                 opt_func=functools.partial(torch.optim.Adam, betas=(0.9, 0.99)), \n",
    "                 loss_func=None, **arch_kwargs):\n",
    "    ds_, acc_, acces_, accmax_, iter_, time_, epochs_, loss_, val_loss_   = [], [], [], [], [], [], [], [], []\n",
    "    datasets = listify(datasets)\n",
    "    for ds in datasets: \n",
    "        db = create_UCR_databunch(ds, scale_by_channel=scale_by_channel, \n",
    "                                  scale_by_sample=scale_by_sample, scale_range=scale_range,)\n",
    "        for i in range(iters):\n",
    "            print('\\n', ds, i)\n",
    "            ds_.append(ds)\n",
    "            iter_.append(i)\n",
    "            epochs_.append(epochs)\n",
    "            model = arch(db.features, db.c, **arch_kwargs).to(defaults.device)\n",
    "            learn = Learner(db, model, opt_func=opt_func, loss_func=loss_func)\n",
    "            learn.metrics = metrics\n",
    "            start_time = time.time()\n",
    "            learn.fit_one_cycle(epochs, max_lr=max_lr, pct_start=pct_start, moms=(.95, .85) if warmup else (.95, .95),\n",
    "                                div_factor=25.0 if warmup else 1., wd=wd)\n",
    "            duration = time.time() - start_time\n",
    "            time_.append('{:.0f}'.format(duration))\n",
    "            early_stop = math.ceil(np.argmin(learn.recorder.losses) / len(learn.data.train_dl))\n",
    "            acc_.append(learn.recorder.metrics[-1][0].item())\n",
    "            acces_.append(learn.recorder.metrics[early_stop - 1][0].item())\n",
    "            accmax_.append(np.max(learn.recorder.metrics))\n",
    "            loss_.append(learn.recorder.losses[-1].item())\n",
    "            val_loss_.append(learn.recorder.val_losses[-1].item())\n",
    "            if len(datasets) * iters >1: clear_output()\n",
    "            df = (pd.DataFrame(np.stack((ds_, iter_, epochs_, loss_, val_loss_ ,acc_, acces_, accmax_, time_)).T,\n",
    "                               columns=['dataset', 'iter', 'epochs', 'loss', 'val_loss', \n",
    "                                        'accuracy', 'accuracy_ts', \n",
    "                                        'max_accuracy', 'time (s)'])\n",
    "                  )\n",
    "            df = df.astype({'loss': float, 'val_loss': float, 'accuracy': float, \n",
    "                            'accuracy_ts': float, 'max_accuracy': float})\n",
    "            display(df)\n",
    "    return learn, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:\n",
    "\n",
    "# Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2019). InceptionTime: Finding AlexNet for Time Series Classification. arXiv preprint arXiv:1909.04939.\n",
    "# Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def noop(x):\n",
    "    return x\n",
    "\n",
    "def shortcut(c_in, c_out):\n",
    "    return nn.Sequential(*[nn.Conv1d(c_in, c_out, kernel_size=1), \n",
    "                           nn.BatchNorm1d(c_out)])\n",
    "    \n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, c_in, bottleneck=32, ks=40, nb_filters=32):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bottleneck = nn.Conv1d(c_in, bottleneck, 1) if bottleneck and c_in > 1 else noop\n",
    "        mts_feat = bottleneck or c_in\n",
    "        conv_layers = []\n",
    "        kss = [ks // (2**i) for i in range(3)]\n",
    "        # ensure odd kss until nn.Conv1d with padding='same' is available in pytorch 1.3\n",
    "        kss = [ksi if ksi % 2 != 0 else ksi - 1 for ksi in kss]  \n",
    "        for i in range(len(kss)):\n",
    "            conv_layers.append(\n",
    "                nn.Conv1d(mts_feat, nb_filters, kernel_size=kss[i], padding=kss[i] // 2))\n",
    "        self.conv_layers = nn.ModuleList(conv_layers)\n",
    "        self.maxpool = nn.MaxPool1d(3, stride=1, padding=1)\n",
    "        self.conv = nn.Conv1d(c_in, nb_filters, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm1d(nb_filters * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        for i in range(3):\n",
    "            out_ = self.conv_layers[i](x)\n",
    "            if i == 0: out = out_\n",
    "            else: out = torch.cat((out, out_), 1)\n",
    "        mp = self.conv(self.maxpool(input_tensor))\n",
    "        inc_out = torch.cat((out, mp), 1)\n",
    "        return self.act(self.bn(inc_out))\n",
    "\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self,c_in,bottleneck=32,ks=40,nb_filters=32,residual=True,depth=6):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = residual\n",
    "        self.depth = depth\n",
    "\n",
    "        #inception & residual layers\n",
    "        inc_mods = []\n",
    "        res_layers = []\n",
    "        res = 0\n",
    "        for d in range(depth):\n",
    "            inc_mods.append(\n",
    "                Inception(c_in if d == 0 else nb_filters * 4, bottleneck=bottleneck if d > 0 else 0,ks=ks,\n",
    "                          nb_filters=nb_filters))\n",
    "            if self.residual and d % 3 == 2:\n",
    "                res_layers.append(shortcut(c_in if res == 0 else nb_filters * 4, nb_filters * 4))\n",
    "                res += 1\n",
    "            else: res_layer = res_layers.append(None)\n",
    "        self.inc_mods = nn.ModuleList(inc_mods)\n",
    "        self.res_layers = nn.ModuleList(res_layers)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inc_mods[d](x)\n",
    "            if self.residual and d % 3 == 2:\n",
    "                res = self.res_layers[d](res)\n",
    "                x += res\n",
    "                res = x\n",
    "                x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "class InceptionTime(nn.Module):\n",
    "    def __init__(self,c_in,c_out,bottleneck=32,ks=40,nb_filters=32,residual=True,depth=6):\n",
    "        super().__init__()\n",
    "        self.block = InceptionBlock(c_in,bottleneck=bottleneck,ks=ks,nb_filters=nb_filters,\n",
    "                                    residual=residual,depth=depth)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(nb_filters * 4, c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        x = self.gap(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:42:10.837080Z",
     "start_time": "2019-10-01T16:42:10.830312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "bottom10 = [ 'Wine', 'BeetleFly',  #'CinCECGtorso', not available for download \n",
    "            'InlineSkate', 'MiddlePhalanxTW', 'OliveOil', 'SmallKitchenAppliances', 'WordSynonyms', \n",
    "            'MiddlePhalanxOutlineAgeGroup', 'MoteStrain', 'Phoneme']\n",
    "top3 = ['Herring', 'ScreenType', 'ChlorineConcentration']\n",
    "datasets = bottom10 + top3\n",
    "bs = 64\n",
    "scale_type = 'standardize'\n",
    "scale_by_channel = True\n",
    "scale_by_sample  = False \n",
    "scale_range = (-1, 1)  \n",
    "\n",
    "# Arch\n",
    "arch = InceptionTime\n",
    "arch_kwargs = dict()\n",
    "\n",
    "# Training\n",
    "iters = 1\n",
    "epochs = 500\n",
    "max_lr = 3e-3\n",
    "warmup = False\n",
    "pct_start = .7\n",
    "metrics = [accuracy]\n",
    "wd = 1e-2\n",
    "opt_func = Ranger\n",
    "loss_func = LabelSmoothingCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:51:01.204577Z",
     "start_time": "2019-10-01T16:42:13.516196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>iter</th>\n",
       "      <th>epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_ts</th>\n",
       "      <th>max_accuracy</th>\n",
       "      <th>time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692424</td>\n",
       "      <td>0.693793</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737083</td>\n",
       "      <td>0.697668</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>InlineSkate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.961044</td>\n",
       "      <td>1.951494</td>\n",
       "      <td>0.152727</td>\n",
       "      <td>0.152727</td>\n",
       "      <td>0.152727</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MiddlePhalanxTW</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.589655</td>\n",
       "      <td>1.749170</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>OliveOil</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.667427</td>\n",
       "      <td>1.428959</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>SmallKitchenAppliances</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.135667</td>\n",
       "      <td>1.109895</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>WordSynonyms</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.382129</td>\n",
       "      <td>3.268570</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>MiddlePhalanxOutlineAgeGroup</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000210</td>\n",
       "      <td>1.080597</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>MoteStrain</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709574</td>\n",
       "      <td>0.690208</td>\n",
       "      <td>0.539137</td>\n",
       "      <td>0.539137</td>\n",
       "      <td>0.539137</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Phoneme</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.737337</td>\n",
       "      <td>3.657671</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Herring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862592</td>\n",
       "      <td>0.729897</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ScreenType</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117127</td>\n",
       "      <td>1.100862</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>ChlorineConcentration</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.032640</td>\n",
       "      <td>1.065673</td>\n",
       "      <td>0.532552</td>\n",
       "      <td>0.532552</td>\n",
       "      <td>0.532552</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dataset iter epochs      loss  val_loss  accuracy  \\\n",
       "0                           Wine    0      1  0.692424  0.693793  0.500000   \n",
       "1                      BeetleFly    0      1  0.737083  0.697668  0.500000   \n",
       "2                    InlineSkate    0      1  1.961044  1.951494  0.152727   \n",
       "3                MiddlePhalanxTW    0      1  1.589655  1.749170  0.272727   \n",
       "4                       OliveOil    0      1  1.667427  1.428959  0.166667   \n",
       "5         SmallKitchenAppliances    0      1  1.135667  1.109895  0.333333   \n",
       "6                   WordSynonyms    0      1  3.382129  3.268570  0.021944   \n",
       "7   MiddlePhalanxOutlineAgeGroup    0      1  1.000210  1.080597  0.571429   \n",
       "8                     MoteStrain    0      1  0.709574  0.690208  0.539137   \n",
       "9                        Phoneme    0      1  3.737337  3.657671  0.004747   \n",
       "10                       Herring    0      1  0.862592  0.729897  0.406250   \n",
       "11                    ScreenType    0      1  1.117127  1.100862  0.333333   \n",
       "12         ChlorineConcentration    0      1  1.032640  1.065673  0.532552   \n",
       "\n",
       "    accuracy_ts  max_accuracy time (s)  \n",
       "0      0.500000      0.500000        2  \n",
       "1      0.500000      0.500000        2  \n",
       "2      0.152727      0.152727       42  \n",
       "3      0.272727      0.272727        5  \n",
       "4      0.166667      0.166667        3  \n",
       "5      0.333333      0.333333       26  \n",
       "6      0.021944      0.021944       12  \n",
       "7      0.571429      0.571429        5  \n",
       "8      0.539137      0.539137        4  \n",
       "9      0.004747      0.004747       72  \n",
       "10     0.406250      0.406250        6  \n",
       "11     0.333333      0.333333       27  \n",
       "12     0.532552      0.532552       25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = run_UCR_test(iters,\n",
    "                      epochs,\n",
    "                      datasets,\n",
    "                      arch,\n",
    "                      bs=bs,\n",
    "                      max_lr=max_lr,\n",
    "                      pct_start=pct_start,\n",
    "                      warmup=warmup,\n",
    "                      wd=wd,\n",
    "                      metrics=metrics,\n",
    "                      scale_type=scale_type,\n",
    "                      scale_by_channel=scale_by_channel,\n",
    "                      scale_by_sample=scale_by_sample,\n",
    "                      scale_range=scale_range,\n",
    "                      opt_func=opt_func,\n",
    "                      loss_func=loss_func,\n",
    "                      **arch_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-v1",
   "language": "python",
   "name": "fastai-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
