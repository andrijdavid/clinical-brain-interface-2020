#AUTOGENERATED! DO NOT EDIT! file to edit: ./TSImageData.ipynb (unless otherwise specified)

import torch
import fastai
from fastai.core import *
from fastai.vision.data import *
from fastai.vision.image import *
from fastai.data_block import *


import numpy as np
import pywt
from scipy import signal
from pyts.image import MarkovTransitionField as MTF
from pyts.image import RecurrencePlot as RP
from pyts.image import GramianAngularField as GAF
from pyts.approximation import PiecewiseAggregateApproximation as PAA
import datetime
device = defaults.device


try: from exp.nb_TSUtilities import *
except ImportError: from .nb_TSUtilities import *
try: from exp.nb_TSBasicData import *
except ImportError: from .nb_TSBasicData import *
try: from exp.nb_TSDataAugmentation import *
except ImportError: from .nb_TSDataAugmentation import *


## All encoders can take a 2d tensor or 2d array
## Output will be a 2d array for gadf, gasf, mtf, rp, ccx, ccy, and 2d tensor for spectro and scalo
# Unify output with ToTensor()


def GADF_encoder(ts, size=None, sample_range=None, overlapping=False,
                 **kwargs):
    ts = To2dArray(ts)
    assert ts.ndim == 2, 'ts ndim must be 2!'
    if size is None: size = ts.shape[-1]
    else: size = min(size, ts.shape[-1])
    encoder = GAF(
        image_size=size,
        sample_range=sample_range,
        method='d',
        overlapping=overlapping)
    output = np.squeeze(encoder.fit_transform(ts), 0)
    return (output + 1) / 2


def GASF_encoder(ts, size=None, sample_range=None, overlapping=False,
                 **kwargs):
    ts = To2dArray(ts)
    assert ts.ndim == 2, 'ts ndim must be 2!'
    if size is None: size = ts.shape[-1]
    else: size = min(size, ts.shape[-1])
    encoder = GAF(
        image_size=size,
        sample_range=sample_range,
        method='s',
        overlapping=overlapping)
    output = np.squeeze(encoder.fit_transform(ts), 0)
    return (output + 1) / 2


def MTF_encoder(ts,
                size=None,
                n_bins=8,
                strategy='quantile',
                overlapping=False,
                **kwargs):
    ts = To2dArray(ts)
    assert ts.ndim == 2, 'ts ndim must be 2!'
    if size is None: size = ts.shape[-1]
    else: size = min(size, ts.shape[-1])
    ts = PAA(window_size=None, output_size=size).fit_transform(ts)
    encoder = MTF(
        size, n_bins=n_bins, strategy=strategy, overlapping=overlapping)
    output = np.squeeze(encoder.fit_transform(ts), 0)
    return output
    #return norm(output)


def RP_encoder(ts,
               size=None,
               dimension=1,
               time_delay=1,
               threshold=None,
               percentage=10,
               norm_output=True,
               **kwargs):
    ts = To2dArray(ts)
    assert ts.ndim == 2, 'ts ndim must be 2!'
    if size is None: size = ts.shape[-1]
    else: size = min(size, ts.shape[-1])
    ts = PAA(window_size=None, output_size=size).fit_transform(ts)
    encoder = RP(
        dimension=dimension,
        time_delay=time_delay,
        threshold=threshold,
        percentage=percentage)
    output = np.squeeze(encoder.fit_transform(ts), 0)
    if norm_output: return norm(output)
    else: return output


def Spectro_encoder(ts,
                    size=None,
                    n_fft=None,
                    hop_length=None,
                    win_length=None,
                    window=None,
                    center=True,
                    pad_mode='reflect',
                    normalized=False,
                    onesided=True,
                    amin=1e-5,
                    spectro_power=1,
                    **kwargs):

    ts = ToTensor(ts)
    assert ts.ndim == 2, 'ts ndim must be 2!'
    if size is None: size = ts.shape[-1]
    else: size = min(size, ts.shape[-1])
    if n_fft is None: n_fft = size
    if hop_length is None: hop_length = 1
    Zxx = torch.stft(
        ts,
        n_fft,
        hop_length=hop_length,
        win_length=win_length,
        window=window,
        center=center,
        pad_mode=pad_mode,
        normalized=normalized,
        onesided=onesided)[0, ..., 0]
    mag = torch.abs(Zxx)
    mag = torch.pow(mag, spectro_power)
    mag = torch.clamp_min(mag, amin)
    mag = torch.log10(mag)
    mag = norm(mag)
    return ToImage(mag, cmap='gray', size=size).data[0]


def Scalo_encoder(ts,
                  size=None,
                  scales=None,
                  wavelet='morl',
                  scalo_power=1,
                  **kwargs):

    # scales is a range
    tslen = ts.shape[-1]
    if size is None: size = tslen
    if scales is None:
        n_scales = min(tslen // 4, 100)
        scales = np.arange(1, n_scales + 1)
    coefs, scales_freq = pywt.cwt(To1dArray(ts), scales, wavelet, 1)
    coefs = torch.Tensor(np.array(coefs, dtype=np.float32)).float()
    values = torch.abs(coefs)
    values = torch.pow(values, scalo_power)
    return ToImage(norm(values), cmap='gray', size=size).data[0]


def AddCoordConv(arr, **kwargs):
    if arr.ndim == 2: arr = arr[None]
    assert arr.ndim == 3, 'arr ndim must be 3!'
    xsize = arr.shape[-1]
    ysize = arr.shape[-2]
    cch = np.repeat(
        np.linspace(0, 1, xsize, dtype=np.float32).reshape(1, -1),
        ysize,
        axis=0)[None]
    ccv = np.repeat(
        np.linspace(0, 1, ysize, dtype=np.float32, axis=-1).reshape(-1, 1),
        xsize,
        axis=1)[None]
    return np.concatenate((arr, cch, ccv))


def get_plot_fig(ts, size, yrange=(-1, 1), dpi=72):
    fig = plt.figure(figsize=(size / dpi, size / dpi))
    ax = plt.axes([0, 0, 1, 1], frameon=False)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    plt.xlim((0, ts.shape[-1]))
    plt.ylim(yrange)
    config = plt.gcf()
    plt.close('all')
    return config


def fig2img(fig, size, return_img=True):
    fig.canvas.draw()
    buf = np.fromstring(
        fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(size, size, 3) / 255
    if return_img: return Image(ToTensor(buf).permute(2, 0, 1))
    else: return ToTensor(buf).permute(2, 0, 1)


def plot(ts, size=None, yrange=(-1, 1), dpi=72, **kwargs):
    if size is None: size = ts.shape[-1]
    fig = get_plot_fig(ts, size, yrange=yrange, dpi=dpi)
    ax = fig.get_axes()[0]
    for tsi in ts:
        ax.plot(tsi, linewidth=1)
    output = fig2img(fig, size).data[0]
    plt.close('all')
    return output


gadf = partial(GADF_encoder)
setattr(gadf, '__name__', 'gadf')
setattr(gadf, '_order', 10)
setattr(gadf, 'cmap', 'spring')
gasf = partial(GASF_encoder)
setattr(gasf, '__name__', 'gasf')
setattr(gasf, '_order', 10)
setattr(gasf, 'cmap', 'summer')
mtf = partial(MTF_encoder)
setattr(mtf, '__name__', 'mtf')
setattr(mtf, '_order', 10)
setattr(mtf, 'cmap', 'autumn')
rp = partial(RP_encoder)
setattr(rp, '__name__', 'rp')
setattr(rp, '_order', 10)
setattr(rp, 'cmap', 'winter')
spectro = partial(Spectro_encoder)
setattr(spectro, '__name__', 'spectro')
setattr(spectro, '_order', 10)
setattr(spectro, 'cmap', 'cool')
scalo = partial(Scalo_encoder)
setattr(scalo, '__name__', 'scalo')
setattr(scalo, '_order', 10)
setattr(scalo, 'cmap', 'jet')
addcc = partial(AddCoordConv)
setattr(addcc, '__name__', 'addcc')
setattr(addcc, '_order', 20)
setattr(addcc, 'cmap', 'viridis')
plot2img = partial(plot, dpi=get_dpi())
setattr(plot2img, '__name__', 'plot2img')
setattr(plot2img, '_order', 20)
setattr(plot2img, 'cmap', None)


def norm(tensor):
    return (tensor - tensor.min()) / (tensor.max() - tensor.min())


def apply_cmap(tensor, cmap=None, **kwargs):
    if cmap is None:
        if tensor.ndim == 2: return tensor[None]
        elif tensor.ndim == 3: return tensor
    assert tensor.ndim == 2, f'incorrect tensor ndim --> {tensor.ndim}'
    return ToTensor(plt.get_cmap(cmap)(tensor))[..., :3].permute(2, 0, 1)


def ToImage(tensor, size=None, cmap=None, **kwargs):
    tensor = torch.Tensor(tensor)
    if tensor.ndim == 1: tensor = tensor[None]
    if cmap is None:
        if tensor.ndim == 2: tensor = tensor[None]
        assert tensor.ndim == 3 or tensor.ndim == 1, f'incorrect tensor ndim --> {tensor.ndim}'
    else:
        if tensor.ndim == 3: tensor = tensor.squeeze(0)
        assert tensor.ndim == 2, f'incorrect tensor ndim --> {tensor.ndim}'
        tensor = apply_cmap(tensor, cmap)
    if size is None: return Image(tensor)
    else: return Image(tensor).resize(size)


def resize_tensor(tensor, size):
    if tensor.ndim == 2: tensor = tensor[None]
    assert tensor.ndim == 3, 'check input tensor ndim'
    return Image(tensor).resize(size).data


def add_dim(tensor, **kwargs):
    return tensor[None]


def _repeat_ch(tensor, **kwargs):
    if tensor.shape[-3] == 3: return tensor
    else: return tensor.repeat(3, 1, 1)


repeat_ch = partial(_repeat_ch)


def _add_zero_ch(tensor, **kwargs):
    if tensor.shape[-3] == 3: return tensor
    elif tensor.shape[-3] == 2:
        zeros = torch.zeros_like(tensor[0][None])
        output = torch.cat([tensor, zeros])
        return output
    else:
        zeros = torch.zeros_like(tensor)
        output = torch.cat([tensor, zeros, zeros])
        return output


add_zero_ch = partial(_add_zero_ch)



class TS2Image():
    use_on_y = False

    def __init__(self,
                 encoders=None,
                 pre=None,
                 post=None,
                 xy_aug=None,
                 add_cc=False,
                 size=224,
                 margin_perc=.1,
                 concatenate=False,
                 apply_colormap=True,
                 repeat_channel=False,
                 **kwargs):

        self.encoders = listify(encoders)
        self.n_encoders = len(self.encoders)
        self.pre = pre
        self.post = post
        self.xy_aug = xy_aug
        self.add_cc = add_cc
        self.size = size
        self.margin_perc = margin_perc
        self.concatenate = concatenate
        self.apply_colormap = apply_colormap
        self.kwargs = kwargs
        funcs = []
        if self.n_encoders > 1 and self.apply_colormap:
            assert self.concatenate == True, 'turn concatenate on to apply colormap'
        for i, encoder in enumerate(self.encoders):
            aug = [partial(To2dArray)]
            aug += [partial(compose(self.pre), **self.kwargs)]
            aug += [partial(encoder, size=self.size, **self.kwargs)]
            if xy_aug: aug += [partial(compose(xyaug), **self.kwargs)]
            if isinstance(apply_colormap, str): aug += [partial(apply_cmap, cmap=apply_colormap)]
            elif apply_colormap: aug += [partial(apply_cmap, cmap=encoder.cmap)]
            elif add_cc: aug += [partial(addcc)]
            else: aug += [partial(add_dim)]
            aug += [partial(ToTensor)]
            funcs.append(compose(aug))
        if repeat_channel: self.outsh = partial(repeat_ch)
        else: self.outsh = partial(add_zero_ch)
        self.funcs = funcs

    def __call__(self, ts):
        assert self.n_encoders > 0, 'You need to select at least 1 encoder'
        output = None
        for ch in range(ts.shape[-2]):
            for i in range(self.n_encoders):
                func = self.funcs[i]
                tensor = func(ts[ch])
                if output is None:
                    output = tensor
                    rs = output.shape
                elif self.concatenate:
                    output = torch.cat(
                        (output, torch.zeros(rs[0], int(rs[1] * self.margin_perc),
                                             rs[2]).float()), 1)
                    output = torch.cat((output, tensor), dim=1)
                else:
                    output = torch.cat((output, tensor), dim=0)
        return self.outsh(output)


def get_fill_between_fig(data, size=224, yrange=(-1, 1), dpi=72):
    fig = plt.figure(figsize=(size / dpi, size / dpi))
    ax = plt.axes([0, 0, 1, 1], frameon=True)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.set_facecolor('black')
    plt.xlim((0, data.shape[-1]))
    plt.ylim(yrange)
    config = plt.gcf()
    plt.close('all')
    return config

def plot_fill_between(data, size=224, yrange=(-1, 1), dpi=DPI, return_img=True):
    data = ToArray(data)
    channels = data.shape[-2]
    assert channels in [2, 3], 'check sel_channels'
    x = np.arange(data.shape[-1])
    fig = get_fill_between_fig(data, size, yrange=yrange, dpi=dpi)
    ax = fig.get_axes()[0]
    if channels == 3:
        ax.fill_between(
            x,
            data[1],
            data[2],
            where=data[1] > data[2],
            facecolor='#0814ff',
            interpolate=True)
        ax.fill_between(
            x,
            data[1],
            data[2],
            where=data[1] < data[2],
            facecolor='#fff308',
            interpolate=True)
    ax.fill_between(
        x,
        data[0],
        data[1],
        where=data[0] > data[1],
        facecolor='#0aff2f',
        interpolate=True)
    ax.fill_between(
        x,
        data[0],
        data[1],
        where=data[0] < data[1],
        facecolor='#ff0ada',
        interpolate=True)
    output = fig2img(fig, size, return_img)
    plt.close('all')
    return output

def get_fill_between_plot(data, sel_TCs=None, sel_channels=None, size=None, return_img=True):
    if size is None: size = data.shape[-1]
    tfs = len(sel_TCs)
    feats = len(sel_channels)
    assert data.shape[-2] == tfs * feats, 'check sel_TCs and sel_channels'
    for j in range(tfs):
        if j == 0:
            ImgData = plot_fill_between(data[j * feats:(j + 1) * feats], size, return_img=False)
        else:
            ImgData = np.concatenate((ImgData,
                                      torch.ones(3, int(size * .05), size),
                                      plot_fill_between(data[j * feats:(j + 1) * feats], size, return_img=False)), axis=1)

    if return_img: return Image(ToTensor(ImgData))
    else: return ToTensor(ImgData)



class TS2ImageList(ItemList):
    "`ItemList` suitable for time series"
    _bunch, _square_show, _square_show_res = ImageDataBunch, True, True

    def __init__(self, items, *args, **kwargs):
        items = To3dTensor(items)
        super().__init__(items, *args, **kwargs)
        self.c, self.size = 3, {}
        self.channels = items.shape[-2]
        self.seq_len = items.shape[-1]

    def get(self, i):
        item = super().get(i)
        return TimeSeriesItem(To2dTensor(item))

    @classmethod
    def from_array(cls, ts, **kwargs):
        return cls(ts)

    @classmethod
    def from_df(cls, df, path='.', cols=0, processor=None,
                **kwargs) -> 'ItemList':
        "Create an `ItemList` in `path` from the inputs in the `cols` of `df`."
        if cols is 0:
            inputs = df
        else:
            col_idxs = df_names_to_idx(list(cols), df)
            inputs = df.iloc[:, col_idxs]
        assert inputs.isna().sum().sum(
        ) == 0, f"You have NaN values in column(s) {cols} of your dataframe, please fix it."
        res = cls(
            items=inputs.values,
            path=path,
            inner_df=df,
            processor=processor,
            **kwargs)
        return res

    @classmethod
    def from_csv(cls, path, csv_name, header='infer', **kwargs) -> 'ItemList':
        "Get the filenames in `path/csv_name` opened with `header`."
        path = Path(path)
        df = pd.read_csv(path / csv_name, header=header)
        return cls.from_df(df, path=path, **kwargs)

    def reconstruct(self, t):
        return Image(t.float().clamp(min=0, max=1))

    def show_xys(self, xs, ys, imgsize=4, figsize=None, **kwargs):
        "Show the `xs` (inputs) and `ys` (targets) on a figure of `figsize`."
        rows = int(np.ceil(math.sqrt(len(xs))))
        axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)
        for x, y, ax in zip(xs, ys, axs.flatten()):
            x.show(ax=ax, y=y, **kwargs)
        for ax in axs.flatten()[len(xs):]:
            ax.axis('off')
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, imgsize=4, figsize=None, **kwargs):
        "Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`."
        if self._square_show_res:
            title = 'Ground truth\nPredictions'
            rows = int(np.ceil(math.sqrt(len(xs))))
            axs = subplots(
                rows,
                rows,
                imgsize=imgsize,
                figsize=figsize,
                title=title,
                weight='bold',
                size=12)
            for x, y, z, ax in zip(xs, ys, zs, axs.flatten()):
                x.show(ax=ax, title=f'{str(y)}\n{str(z)}', **kwargs)
            for ax in axs.flatten()[len(xs):]:
                ax.axis('off')
        else:
            title = 'Ground truth/Predictions'
            axs = subplots(
                len(xs),
                2,
                imgsize=imgsize,
                figsize=figsize,
                title=title,
                weight='bold',
                size=14)
            for i, (x, y, z) in enumerate(zip(xs, ys, zs)):
                x.show(ax=axs[i, 0], y=y, **kwargs)
                x.show(ax=axs[i, 1], y=z, **kwargs)